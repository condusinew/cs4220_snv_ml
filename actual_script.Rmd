---
getwd(title: "ML project"
output: html_document
date: "2025-02-12"
---

```{r}
setwd("/Users/cindyyu/Desktop/CS4220")
library(readxl)
library(tidyverse)
library(caTools)

#random forest
library(randomForest)
library(caret)
library(VIM)
library(ggplot2)
library(mice)
```

#READING IN FILTER PREDICTIONS
```{r}

real1_df <- read.table("snv-parse-real1.txt", header = T)
real2.1_df <- read.table("snv-parse-real2_part1.txt", header = T)
syn1_df <- read.table("snv-parse-syn1.txt", header = T)
syn2_df <- read.table("snv-parse-syn2.txt", header = T)
syn3_df <- read.table("snv-parse-syn3.txt", header = T)
syn4_df <- read.table("snv-parse-syn4.txt", header = T)
syn5_df <- read.table("snv-parse-syn5.txt", header = T)

all_df <- rbind(real1_df, real2.1_df, syn1_df, syn2_df, syn3_df, syn4_df, syn5_df)

rm(real1_df, real2.1_df, syn1_df, syn2_df, syn3_df, syn4_df, syn5_df)

```

#READING IN TRUTHS

```{r}
#add headers: chromosome #, genomic start, genomic stop
real1_truth <- as.data.frame(read.table("/Users/cindyyu/Desktop/CS4220/Data/real1/real1_truth.bed",
                                header = FALSE, sep="\t",stringsAsFactors=FALSE, quote=""))
real2.1_truth <- as.data.frame(read.table("/Users/cindyyu/Desktop/CS4220/Data/real2_part1/real2_truth_chr1to5.bed",
                                header = FALSE, sep="\t",stringsAsFactors=FALSE, quote=""))
syn1_truth <- as.data.frame(read.table("/Users/cindyyu/Desktop/CS4220/Data/syn1/syn1_truth.bed",
                                header = FALSE, sep="\t",stringsAsFactors=FALSE, quote=""))
syn2_truth <- as.data.frame(read.table("/Users/cindyyu/Desktop/CS4220/Data/syn2/syn2_truth.bed",
                                header = FALSE, sep="\t",stringsAsFactors=FALSE, quote=""))
syn3_truth <- as.data.frame(read.table("/Users/cindyyu/Desktop/CS4220/Data/syn3/syn3_truth.bed",
                                header = FALSE, sep="\t",stringsAsFactors=FALSE, quote=""))
syn4_truth <- as.data.frame(read.table("/Users/cindyyu/Desktop/CS4220/Data/syn4/syn4_truth.bed",
                                header = FALSE, sep="\t",stringsAsFactors=FALSE, quote=""))
syn5_truth <- as.data.frame(read.table("/Users/cindyyu/Desktop/CS4220/Data/syn5/syn5_truth.bed",
                                header = FALSE, sep="\t",stringsAsFactors=FALSE, quote=""))
alltruth_df <- rbind(real1_truth, real2.1_truth, syn1_truth, syn2_truth, syn3_truth, syn4_truth, syn5_truth)

names(alltruth_df) <- c("Chr", "START_POS_REF", "END_POS_REF")

write.table(alltruth_df, "all_truths.bed",row.names = F,col.names = F, sep="\t", quote=FALSE)
rm(real1_truth, real2.1_truth, syn1_truth, syn2_truth, syn3_truth, syn4_truth, syn5_truth)
```


```{r}
alltruth_df <- alltruth_df %>% mutate(TRUTH = TRUE)

df3 <- all_df %>% 
  left_join(alltruth_df, by=c('Chr','START_POS_REF', 'END_POS_REF'))

df3$TRUTH <- replace_na(df3$TRUTH, FALSE)

```



#DATA IMPUTATION
```{r}
#SHOWING WHERE TRUE FALSES ARE
#MUTECT
df_m2na <- df3 |> 
  group_by(FILTER_Mutect2, is.na(m2_MQ)) |>
  tally() 

colnames(df_m2na)<- c("FILTER_Mutect2","Is_NA","n")

gg_m2na <- ggplot(df_m2na, aes(fill=Is_NA, y=n, x=FILTER_Mutect2)) + 
    geom_bar(stat="identity", width = 0.7)

#FREEBAYES
df_fbna <- df3 |> 
  group_by(FILTER_Freebayes, is.na(f_MQMR)) |>
  tally() 

colnames(df_fbna)<- c("FILTER_Freebayes","Is_NA","n")

gg_fbna <- ggplot(df_fbna, aes(fill=Is_NA, y=n, x=FILTER_Freebayes)) + 
    geom_bar(stat="identity", width = 0.7)


#VARDICT
df_vdna <- df3 |> 
  group_by(FILTER_Vardict, is.na(vd_SSF), is.na(vd_MSI)) |>
  tally() 

df_vdna <- df_vdna[-3]
colnames(df_vdna)<- c("FILTER_Vardict","Is_NA","n")

#MENTION THAT NA IN SSV ALSO HAD NA IN MSI
gg_vdna <- ggplot(df_vdna, aes(fill=Is_NA, y=n, x=FILTER_Vardict)) + 
    geom_bar(stat="identity", width = 0.7)

#VARSCAN
df_vsna <- df3 |> 
  group_by(FILTER_Varscan, is.na(vs_SPV), is.na(vs_SSC)) |>
  tally() 

df_vsna <- df_vsna[-3]
colnames(df_vsna)<- c("FILTER_Varscan","Is_NA","n")

#MENTION THAT NA IN SSV ALSO HAD NA IN MSI
gg_vsna <- ggplot(df_vsna, aes(fill=Is_NA, y=n, x=FILTER_Varscan)) + 
    geom_bar(stat="identity", width = 0.7)



df3 %>%
  ggplot(aes(x = FILTER_Mutect2, y = m2_MQ)) +
  geom_bar(stat = "identity")


```


```{r}

#replace NAs w MEAN
df3_narm <- df3 %>% mutate_all(~ifelse(is.na(.x), mean(.x, na.rm = TRUE), .x)) 

# #grouped replacing NAs w mean 
# df_groupmean <- df3 %>%
#   group_by(FILTER_Mutect2) %>%
#   mutate(m2_MQ = ifelse(is.na(m2_MQ), mean(m2_MQ, na.rm = TRUE), m2_MQ)) |>
#   ungroup() %>%
#   group_by(FILTER_Freebayes) %>%
#   mutate(f_MQMR = ifelse(is.na(f_MQMR), mean(f_MQMR, na.rm = TRUE), f_MQMR)) %>%
#   ungroup() %>%
#   group_by(FILTER_Vardict) %>%
#   mutate(vd_SSF = ifelse(is.na(vd_SSF), mean(vd_SSF, na.rm = TRUE), vd_SSF)) %>%
#   ungroup() %>%
#   group_by(FILTER_Vardict) %>%
#   mutate(vd_MSI = ifelse(is.na(vd_MSI), mean(vd_MSI, na.rm = TRUE), vd_MSI)) %>%
#   ungroup() %>%
#   group_by(FILTER_Varscan) %>%
#   mutate(vs_SSC = ifelse(is.na(vs_SSC), mean(vd_MSI, na.rm = TRUE), vs_SSC)) %>%
#   ungroup() %>%
#   group_by(FILTER_Varscan) %>%
#   mutate(vs_SPV = ifelse(is.na(vs_SPV), mean(vs_SPV, na.rm = TRUE), vs_SPV)) %>%
#   ungroup()

df_groupmedian <- df3 %>%
  group_by(FILTER_Mutect2) %>%
  mutate(m2_MQ = ifelse(is.na(m2_MQ), median(m2_MQ, na.rm = TRUE), m2_MQ)) |>
  ungroup() %>%
  group_by(FILTER_Freebayes) %>%
  mutate(f_MQMR = ifelse(is.na(f_MQMR), median(f_MQMR, na.rm = TRUE), f_MQMR)) %>%
  ungroup() %>%
  group_by(FILTER_Vardict) %>%
  mutate(vd_SSF = ifelse(is.na(vd_SSF), median(vd_SSF, na.rm = TRUE), vd_SSF)) %>%
  ungroup() %>%
  group_by(FILTER_Vardict) %>%
  mutate(vd_MSI = ifelse(is.na(vd_MSI), median(vd_MSI, na.rm = TRUE), vd_MSI)) %>%
  ungroup() %>%
  group_by(FILTER_Varscan) %>%
  mutate(vs_SSC = ifelse(is.na(vs_SSC), median(vd_MSI, na.rm = TRUE), vs_SSC)) %>%
  ungroup() %>%
  group_by(FILTER_Varscan) %>%
  mutate(vs_SPV = ifelse(is.na(vs_SPV), median(vs_SPV, na.rm = TRUE), vs_SPV)) %>%
  ungroup()


df_groupmedian <- df3 %>%
  group_by(FILTER_Mutect2, FILTER_Freebayes, FILTER_Vardict, FILTER_Varscan) %>%
  summarize(median(m2_MQ))

df_groupmedian <- df3 %>%
  group_by(FILTER_Freebayes) %>%
  summarize(median(f_MQMR))
```

#MICE

```{r}
md.pattern(df3)

df_hmm <- df3[, 9:19]


library(VIM)
aggr_plot <- aggr(df3, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(df3), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))

```



```{r}
#missForest
library(missForest)

df3_features <- df3[13:19]
# df3_features$FILTER_Mutect2 = as.factor(df3_features$FILTER_Mutect2)
# df3_features$FILTER_Freebayes = as.factor(df3_features$FILTER_Freebayes)
# df3_features$FILTER_Vardict = as.factor(df3_features$FILTER_Vardict)
# df3_features$FILTER_Varscan = as.factor(df3_features$FILTER_Varscan)
df3_features$TRUTH = as.factor(df3_features$TRUTH)

library(mice)
#seed 10% missing values
df3.mis <- prodNA(df3_features, noNA = 0.1)
summary(df3.mis)

imputed_Data <- mice(df3.mis, m=5, maxit = 50, method = 'pmm', seed = 500)
summary(imputed_Data)


complete_data <- complete(imputed_Data, action = "long")

# Compare variance before and after imputation
var_original <- apply(df3, 2, var, na.rm = TRUE)
var_imputed <- apply(complete_data, 2, var)

# Scatter plot to compare
plot(var_original, var_imputed, main="Variance Comparison (Original vs. Imputed)")
abline(0,1, col="red") # Ideal case where variance is preserved

completeData1 <- complete(imputed_Data, 1)
completeData2 <- complete(imputed_Data, 2)
completeData3 <- complete(imputed_Data, 3)
completeData4 <- complete(imputed_Data, 4)
completeData5 <- complete(imputed_Data, 5)

write.table(completeData1, "impute_mice1.txt", row.names = F,col.names = F, sep=",", quote=FALSE)
write.table(completeData2, "impute_mice2.txt", row.names = F,col.names = F, sep=",", quote=FALSE)
write.table(completeData3, "impute_mice3.txt", row.names = F,col.names = F, sep=",", quote=FALSE)
write.table(completeData4, "impute_mice4.txt", row.names = F,col.names = F, sep=",", quote=FALSE)
write.table(completeData5, "impute_mice5.txt", row.names = F,col.names = F, sep=",", quote=FALSE)

read.table("impute_mice5.txt", header = F, sep = ',')
```


#MACHINE LEARNING 
```{r}
#remove chr and genomic start/stop

library(rpart)

#splitting
#SOMEHOW REMOVE COLUMNS OF GENOME NUMBER AND CHR
split_vals <- sample.split(df3_narm $TRUTH, SplitRatio = 0.80)
train_set <- subset(df3_narm, split_vals == TRUE)
test_set <- subset(df3_narm, split_vals == FALSE)

train_set_split <- train_set[,-(1:8)]

#model
rpart(as.factor(TRUTH)~ ., data = train_set_split) -> mod_class
predict(mod_class, test_set, type = 'class') -> result_class
table(test_set$TRUTH, result_class)

#refitting predictions to be bed file
#REALIZED I SHOULDNT HAVE UPENDED TO DF3, BUT RATHER TEST SET!
predictions <- data.frame(Chr = test_set$Chr,
                          START_POS_REF = test_set$START_POS_REF,
                          END_POS_REF = test_set$END_POS_REF, 
                          TRUTH=result_class)

predictions <- predictions |>
  filter(TRUTH == TRUE) 

my_predictions <- predictions[, -4]

write.table(my_predictions, "my-predictions.bed",row.names = F,col.names = F, sep="\t", quote=FALSE) 


#change columsn to remove chromo number
#treat diff samples differently

```

#RANDOM FOREST ATTEMPT - CINDY
```{r}





----------------------------------------------------------------------------------------------------------------------

neha 

-------------------------------------------------------------------------------------------------------------------------


ALSOOOOO 

for knn: 

# Step 1: Install and load the VIM package if you haven't already
install.packages("VIM")
library(VIM)

# Step 2: Perform KNN imputation only on specific variables
data <- kNN(new_data, variable = c("EducationLevel", "DietPerception"), k = 5)

# Step 3: Verify that missing values have been imputed
summary(data)

---
getwd(title: "ML project"
output: html_document
date: "2025-02-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
setwd("C:/Users/nehar/OneDrive - Victoria University of Wellington - STUDENT/EXCHANGE/ACADEMICS/CS/FOR THE PROJECT")

install.packages("readxl", "tidyverse", "caTools")

install.packages("knitr") 


install.packages("dplyr")


library(dplyr)


library(readxl)
library(tidyverse)
library(caTools)
library(knitr)
```

#READING IN FILTER PREDICTIONS
```{r}
real1_df <- read.table("snv-parse-real1.txt", header = T)
#real2.1_df <- read.table("snv-parse-real2_part1.txt", header = T)
real2.1_df <- read.table("snv-parse-real2_part1.txt ", header = T)
real2.2_df <- read.table("snv-parse-real2_part2.txt", header = T)

syn1_df <- read.table("snv-parse-syn1.txt", header = T)
syn2_df <- read.table("snv-parse-syn2.txt", header = T)
syn3_df <- read.table("snv-parse-syn3.txt", header = T)
syn4_df <- read.table("snv-parse-syn4.txt", header = T)
syn5_df <- read.table("snv-parse-syn5.txt", header = T)

all_df <- rbind(real1_df, real2.2_df, real2.2_df, syn1_df, syn2_df, syn3_df, syn4_df, syn5_df)

head(all_df)

```


```{r}

#looking for NA's
summary(all_df)



```
#READING IN TRUTHS

```{r}

file.exists("C:/Users/nehar/OneDrive - Victoria University of Wellington - STUDENT/EXCHANGE/ACADEMICS/CS/real1_truth.bed")


```

```{r}


real1_truth <- as.data.frame(read.table("C:/Users/nehar/OneDrive - Victoria University of Wellington - STUDENT/EXCHANGE/ACADEMICS/CS/real1_truth.bed",
                                       header = FALSE, sep="\t", stringsAsFactors=FALSE, quote=""))



real2.1_truth <- as.data.frame(read.table("C:/Users/nehar/OneDrive - Victoria University of Wellington - STUDENT/EXCHANGE/ACADEMICS/CS/real2_truth_chr1to5.bed",
                                          header = FALSE, sep="\t", stringsAsFactors=FALSE, quote=""))



syn1_truth <- as.data.frame(read.table("C:/Users/nehar/OneDrive - Victoria University of Wellington - STUDENT/EXCHANGE/ACADEMICS/CS/syn1_truth.bed",
                                       header = FALSE, sep="\t", stringsAsFactors=FALSE, quote=""))


syn2_truth <- as.data.frame(read.table("C:/Users/nehar/OneDrive - Victoria University of Wellington - STUDENT/EXCHANGE/ACADEMICS/CS/syn2_truth.bed",
                                       header = FALSE, sep="\t", stringsAsFactors=FALSE, quote=""))


syn3_truth <- as.data.frame(read.table("C:/Users/nehar/OneDrive - Victoria University of Wellington - STUDENT/EXCHANGE/ACADEMICS/CS/syn3_truth.bed",
                                       header = FALSE, sep="\t", stringsAsFactors=FALSE, quote=""))


syn4_truth <- as.data.frame(read.table("C:/Users/nehar/OneDrive - Victoria University of Wellington - STUDENT/EXCHANGE/ACADEMICS/CS/syn4_truth.bed",
                                       header = FALSE, sep="\t", stringsAsFactors=FALSE, quote=""))


syn5_truth <- as.data.frame(read.table("C:/Users/nehar/OneDrive - Victoria University of Wellington - STUDENT/EXCHANGE/ACADEMICS/CS/syn5_truth.bed",
                                       header = FALSE, sep="\t", stringsAsFactors=FALSE, quote=""))



alltruth_df <- rbind(real1_truth, real2.1_truth, syn1_truth, syn2_truth, syn3_truth, syn4_truth, syn5_truth)


names(alltruth_df) <- c("Chr", "START_POS_REF", "END_POS_REF")




head(alltruth_df)


```

```{r}

#thought: should we weight the real information more?
#GET RID OF CORREXT X AND Y
#MAKE COLUMN ALL TRUE IN ALL TRUTH
alltruth_df <- alltruth_df %>% mutate(TRUTH = TRUE)


df3 <- all_df %>% 
  left_join(alltruth_df, by=c('Chr','START_POS_REF', 'END_POS_REF'))


all_df <- all_df %>%
  left_join(alltruth_df %>% mutate(TRUTH = TRUE), 
            by = c("Chr", "START_POS_REF", "END_POS_REF")) 
 

all_df <- all_df %>%
  mutate(correct = any(alltruth_df$Chr == Chr & alltruth_df$START_POS_REF == START_POS_REF &
                         alltruth_df$END_POS_REF == END_POS_REF))

```



#CREATING BENCHMARKS 

## consensus between at least 2

```{r}
consensus_df <- all_df %>%
  mutate(two_plus = rowSums(select(., FILTER_Mutect2, FILTER_Freebayes, FILTER_Varscan, FILTER_Vardict)) >= 2)
```

handelling missing data :)

```{r}



all_df <- all_df %>%
  mutate(across(everything(), 
                ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))


summary(all_df)




```


```{r}
plot(lm_model$fitted.values, lm_model$residuals)
abline(h = 0, col = "red")
```


EDA:

ok idk how helpful this one is: 

```{r}

  
  install.packages("tidyverse")
  
  
  install.packages("ggcorrplot")
  
  

  library(tidyverse)
  library(ggcorrplot)  # for correlation heatmap
  
 olumns
  numeric_cols <- all_df %>% 
    select(m2_MQ, f_MQMR, vs_SSC, vs_SPV, vd_SSF, vd_MSI)
  

  numeric_cols <- numeric_cols %>%
    mutate(across(everything(), ~ifelse(is.na(.), median(., na.rm = TRUE), .)))
  
 
 
  cor_matrix <- cor(numeric_cols, use = "pairwise.complete.obs")
  
  
  ggcorrplot(cor_matrix, lab = TRUE, type = "lower", title = "Correlation Matrix")
  

```

eda: na values

```{r}


library(ggplot2)


na_count <- sapply(all_df, function(x) sum(is.na(x)))
na_percentage <- sapply(all_df, function(x) mean(is.na(x)))


na_df <- data.frame(Column = names(na_percentage), NA_Percentage = na_percentage)
ggplot(na_df, aes(x = reorder(Column, NA_Percentage), y = NA_Percentage)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "NA Distribution in Columns", x = "Columns", y = "Percentage of NAs") +
  theme_minimal()


missing_indicators <- all_df %>%
  mutate(across(everything(), ~ ifelse(is.na(.), 1, 0), .names = "missing_{.col}"))


all_df_with_missing_indicators <- cbind(all_df, missing_indicators)

head(all_df_with_missing_indicators)



```



#MACHINE LEARNING NARM

```{r}

#install.packages("randomForest")

  library(randomForest)
  library(caTools)
 
df3_narm <- df3 %>% mutate_all(~ifelse(is.na(.x), mean(.x, na.rm = TRUE), .x)) 
 
  #converting to factor!!!!!
 
  df3_narm$TRUTH <- as.factor(df3_narm$TRUTH)
 
  set.seed(123)
 
 
  split <- sample.split(df3_narm$TRUTH, SplitRatio = 0.8)
 
 
  training_set <- subset(df3_narm, split == TRUE)
  test_set <- subset(df3_narm, split == FALSE)
 
 
  #rf_model <- randomForest(correct ~ ., data = training_set, importance = TRUE)
 
  rf_model_mean <- randomForest(TRUTH ~ ., data = training_set, ntree = 100, importance = TRUE)
 
  importance(rf_model_mean)
 
  test_predictions_mean <- predict(rf_model_mean, newdata = test_set)
 
  
  confusion_matrix_mean <- table(test_set$TRUTH, test_predictions_mean)
  print(confusion_matrix_mean) #F1: 0.9926
 
 
  importance(rf_model)
  varImpPlot(rf_model)


  test_pred <- test_predictions_mean
 # write.table(test_pred, "test_predictions_vector.bed",row.names = F,col.names = F, sep="\t", quote=FALSE)

  #test_pred <-read.table("REALtest_predictions.bed", sep="\t" )
  
  
  #PREDICTIONS INTO BED
  test_setnew <- test_set[,1:3] 
  test_setnew$TRUTH <- test_pred
  
  test_setnew <- test_setnew |>
    filter(TRUTH == TRUE)
  
  test_setnew <- test_setnew[1:3]
  
  
  write.table(test_set, "meantest_predictions.bed",row.names = F,col.names = F, sep="\t", quote=FALSE)
  
  #TEST SET INTO BED
testset_truth <- test_set[, -(4:18)] |>
    filter(TRUTH == TRUE)
  
  
  write.table(testset_truth, "meantest_TRUTH.bed",row.names = F,col.names = F, sep="\t", quote=FALSE)
```

##MACHINE LEARNING SINGLE CASE IMPUTATION MEDIAN

```{r}

df_groupmedian$TRUTH <- as.factor(df_groupmedian$TRUTH)

set.seed(123)


split <- sample.split(df_groupmedian$TRUTH, SplitRatio = 0.8)


training_set <- subset(df_groupmedian, split == TRUE)
test_set <- subset(df_groupmedian, split == FALSE)


#rf_model <- randomForest(correct ~ ., data = training_set, importance = TRUE)

rf_model_median <- randomForest(TRUTH ~ ., data = training_set, ntree = 100, importance = TRUE)

#0.9930
test_predictions_median <- predict(rf_model_median, newdata = test_set)

confusion_matrix <- table(test_set$TRUTH, test_predictions_median)
print(confusion_matrix)



importance(rf_model)
varImpPlot(rf_model)


test_pred <- test_predictions
write.table(test_pred, "mediantest_predictions.bed",row.names = F,col.names = F, sep="\t", quote=FALSE)

#test_pred <-read.table("REALtest_predictions.bed", sep="\t" )


#PREDICTIONS INTO BED
test_setnew <- test_set[,1:3] 
test_setnew$TRUTH <- test_pred

test_setnew <- test_setnew |>
  filter(TRUTH == TRUE)

test_setnew <- test_setnew[1:3]


write.table(test_set, "mediantest_predictions.bed",row.names = F,col.names = F, sep="\t", quote=FALSE)

#TEST SET INTO BED
testset_truth <- test_set[, -(4:18)] |>
  filter(TRUTH == TRUE)


write.table(testset_truth, "mediantest_TRUTH",row.names = F,col.names = F, sep="\t", quote=FALSE)
```



##MACHINE LEARNING SINGLE CASE IMPUTATION MEDIAN

```{r}

set.seed(123)

mice1 <- read.table('impute_mice1.txt', sep = ',', col.names = c("m2_MQ", "f_MQMR", "vs_SSC", "vs_SPV", "vd_SSF", "vs_MSI", "TRUTH"))

df_mice1 <- df3
df_mice1[13:19] <- mice1

df_mice1$TRUTH <- as.factor(df_mice1$TRUTH)
split <- sample.split(df_mice1$TRUTH, SplitRatio = 0.8)


training_set <- subset(df_mice1, split == TRUE)
test_set <- subset(df_mice1, split == FALSE)


#rf_model <- randomForest(correct ~ ., data = training_set, importance = TRUE)

rf_model_mice <- randomForest(TRUTH ~ ., data = training_set, ntree = 100, importance = TRUE)


test_predictions_mice <- predict(rf_model_mice, newdata = test_set)

confusion_matrix_mice <- table(test_set$TRUTH, test_predictions_mice)
print(confusion_matrix_mice)



importance(rf_model)
varImpPlot(rf_model)


test_pred <- test_predictions
write.table(test_pred, "test_predictions_vector.bed",row.names = F,col.names = F, sep="\t", quote=FALSE)

#test_pred <-read.table("REALtest_predictions.bed", sep="\t" )


#PREDICTIONS INTO BED
test_setnew <- test_set[,1:3] 
test_setnew$TRUTH <- test_pred

test_setnew <- test_setnew |>
  filter(TRUTH == TRUE)

test_setnew <- test_setnew[1:3]


write.table(test_set, "REALtest_predictions.bed",row.names = F,col.names = F, sep="\t", quote=FALSE)

#TEST SET INTO BED
testset_truth <- test_set[, -(4:18)] |>
  filter(TRUTH == TRUE)


write.table(testset_truth, "REALtest_TRUTH.bed",row.names = F,col.names = F, sep="\t", quote=FALSE)
```

```{r}
df3_median <- df3 %>% mutate_all(~ifelse(is.na(.x), median(.x, na.rm = TRUE), .x)) 
 
  #converting to factor!!!!!
 
  df3_median$TRUTH <- as.factor(df3_median$TRUTH)
 
  set.seed(123)
 
 
  split <- sample.split(df3_median$TRUTH, SplitRatio = 0.8)
 
 
  training_set <- subset(df3_median, split == TRUE)
  test_set <- subset(df3_median, split == FALSE)
 
 
  #rf_model <- randomForest(correct ~ ., data = training_set, importance = TRUE)
 
  rf_model_median <- randomForest(TRUTH ~ ., data = training_set, ntree = 100, importance = TRUE)
 
 
  test_predictions_median <- predict(rf_model_median, newdata = test_set)
 
  
  confusion_matrix_median <- table(test_set$TRUTH, test_predictions_median)
  print(confusion_matrix_median) #F1: 0.9926
 
```
```{r}
install.packages("pROC")
library(pROC)

length(test_set)

roc_curve <- roc(test_set$TRUTH, test_predictions_median[, 4])

#plott!!
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)


auc_value <- auc(roc_curve)
print(paste("AUC: ", auc_value))


confusion_matrix <- table(test_set$correct, predict(rf_model, newdata = test_set))
print(confusion_matrix)

```

=
```{r}
importance(rf_model_mice)
```
